{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a82df7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page 1...\n",
      "Processing page 2...\n",
      "Processing page 3...\n",
      "Processing page 4...\n",
      "Processing page 5...\n",
      "Processing page 6...\n",
      "Processing page 7...\n",
      "Processing page 8...\n",
      "Processing page 9...\n",
      "Processing page 10...\n",
      "Processing page 11...\n",
      "Processing page 12...\n",
      "Processing page 13...\n",
      "Processing page 14...\n",
      "Processing page 15...\n",
      "Processing page 16...\n",
      "Processing page 17...\n",
      "Processing page 18...\n",
      "Processing page 19...\n",
      "Processing page 20...\n",
      "Processing page 21...\n",
      "Processing page 22...\n",
      "Processing page 23...\n",
      "Processing page 24...\n",
      "Processing page 25...\n",
      "Processing page 26...\n",
      "Processing page 27...\n",
      "Processing page 28...\n",
      "Processing page 29...\n",
      "Processing page 30...\n",
      "Processing page 31...\n",
      "Processing page 32...\n",
      "Processing page 33...\n",
      "Processing page 34...\n",
      "Processing page 35...\n",
      "Processing page 36...\n",
      "Processing page 37...\n",
      "Processing page 38...\n",
      "Processing page 39...\n",
      "Processing page 40...\n",
      "Processing page 41...\n",
      "Processing page 42...\n",
      "Processing page 43...\n",
      "Processing page 44...\n",
      "Processing page 45...\n",
      "Processing page 46...\n",
      "Processing page 47...\n",
      "Processing page 48...\n",
      "Processing page 49...\n",
      "Processing page 50...\n",
      "Processing page 51...\n",
      "Processing page 52...\n",
      "Processing page 53...\n",
      "Processing page 54...\n",
      "Processing page 55...\n",
      "Processing page 56...\n",
      "Processing page 57...\n",
      "Processing page 58...\n",
      "Processing page 59...\n",
      "Processing page 60...\n",
      "Processing page 61...\n",
      "Processing page 62...\n",
      "Processing page 63...\n",
      "Processing page 64...\n",
      "Processing page 65...\n",
      "Processing page 66...\n",
      "Processing page 67...\n",
      "Processing page 68...\n",
      "Processing page 69...\n",
      "Processing page 70...\n",
      "Processing page 71...\n",
      "Processing page 72...\n",
      "Processing page 73...\n",
      "Processing page 74...\n",
      "Processing page 75...\n",
      "Processing page 76...\n",
      "Processing page 77...\n",
      "Processing page 78...\n",
      "Processing page 79...\n",
      "Processing page 80...\n",
      "Processing page 81...\n",
      "Processing page 82...\n",
      "Processing page 83...\n",
      "Processing page 84...\n",
      "Processing page 85...\n",
      "Processing page 86...\n",
      "Processing page 87...\n",
      "Processing page 88...\n",
      "Processing page 89...\n",
      "Processing page 90...\n",
      "Processing page 91...\n",
      "Processing page 92...\n",
      "Processing page 93...\n",
      "Processing page 94...\n",
      "Processing page 95...\n",
      "Processing page 96...\n",
      "Processing page 97...\n",
      "Processing page 98...\n",
      "Processing page 99...\n",
      "Processing page 100...\n",
      "Processing page 101...\n",
      "Processing page 102...\n",
      "Processing page 103...\n",
      "Processing page 104...\n",
      "Processing page 105...\n",
      "Processing page 106...\n",
      "Processing page 107...\n",
      "Processing page 108...\n",
      "Processing page 109...\n",
      "Processing page 110...\n",
      "Processing page 111...\n",
      "Processing page 112...\n",
      "Processing page 113...\n",
      "Processing page 114...\n",
      "Processing page 115...\n",
      "Processing page 116...\n",
      "Processing page 117...\n",
      "Processing page 118...\n",
      "Processing page 119...\n",
      "Processing page 120...\n",
      "Processing page 121...\n",
      "Processing page 122...\n",
      "Processing page 123...\n",
      "Processing page 124...\n",
      "Processing page 125...\n",
      "Processing page 126...\n",
      "Processing page 127...\n",
      "Processing page 128...\n",
      "Processing page 129...\n",
      "Processing page 130...\n",
      "Processing page 131...\n",
      "Processing page 132...\n",
      "Processing page 133...\n",
      "Processing page 134...\n",
      "Processing page 135...\n",
      "Processing page 136...\n",
      "Processing page 137...\n",
      "Processing page 138...\n",
      "Processing page 139...\n",
      "Processing page 140...\n",
      "Processing page 141...\n",
      "Processing page 142...\n",
      "Processing page 143...\n",
      "Processing page 144...\n",
      "Processing page 145...\n",
      "Processing page 146...\n",
      "Processing page 147...\n",
      "Processing page 148...\n",
      "Processing page 149...\n",
      "Processing page 150...\n",
      "Processing page 151...\n",
      "Processing page 152...\n",
      "Processing page 153...\n",
      "Processing page 154...\n",
      "Processing page 155...\n",
      "Processing page 156...\n",
      "Processing page 157...\n",
      "Processing page 158...\n",
      "Processing page 159...\n",
      "Processing page 160...\n",
      "Processing page 161...\n",
      "Processing page 162...\n",
      "Processing page 163...\n",
      "Processing page 164...\n",
      "Processing page 165...\n",
      "Processing page 166...\n",
      "Processing page 167...\n",
      "Processing page 168...\n",
      "Processing page 169...\n",
      "Processing page 170...\n",
      "Processing page 171...\n",
      "Processing page 172...\n",
      "Processing page 173...\n",
      "Processing page 174...\n",
      "All pages saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Create folder to save HTML files\n",
    "output_folder = \"tnea_pages\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "driver = webdriver.Firefox()\n",
    "\n",
    "driver.get(\"https://cutoff.tneaonline.org/\")\n",
    "\n",
    "# Wait for the page and reCAPTCHA iframe to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Switch to the reCAPTCHA iframe and click checkbox\n",
    "iframe = driver.find_element(By.CSS_SELECTOR, \"iframe[src*='recaptcha']\")\n",
    "driver.switch_to.frame(iframe)\n",
    "checkbox = driver.find_element(By.ID, \"recaptcha-anchor\")\n",
    "checkbox.click()\n",
    "\n",
    "# Switch back to main content\n",
    "driver.switch_to.default_content()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "# Click the submit button\n",
    "submit_button = driver.find_element(By.CSS_SELECTOR, \"input[type='submit'][value='Proceed']\")\n",
    "submit_button.click()\n",
    "\n",
    "# Wait for the results page to load\n",
    "time.sleep(10)  # Increase if loading is slow\n",
    "\n",
    "# Loop through all 174 pages\n",
    "for page_number in range(1, 175):\n",
    "    print(f\"Processing page {page_number}...\")\n",
    "\n",
    "    # Find the pagination link for the page number\n",
    "    try:\n",
    "        link = driver.find_element(By.XPATH, f\"//ul[contains(@class, 'pagination')]//a[text()='{page_number}']\")\n",
    "        link.click()\n",
    "    except Exception as e:\n",
    "        print(f\"Could not find or click page {page_number}: {e}\")\n",
    "        break\n",
    "\n",
    "    # Wait for the page content to update\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Save the page source\n",
    "    html = driver.page_source\n",
    "    filename = os.path.join(output_folder, f\"page_{page_number}.html\")\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html)\n",
    "\n",
    "driver.quit()\n",
    "print(\"All pages saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e5f2761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped 3474 rows from 174 HTML files and saved to 'tnea_data.json'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the folder containing all HTML files\n",
    "folder_path = \"tnea_pages\"\n",
    "\n",
    "# List to store all rows\n",
    "all_rows = []\n",
    "\n",
    "# Loop through all HTML files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".html\"):\n",
    "        filepath = os.path.join(folder_path, filename)\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "            soup = BeautifulSoup(file, \"html.parser\")\n",
    "\n",
    "            # Find the table with the class name\n",
    "            table = soup.find(\"table\", class_=\"table table-striped table-bordered table-hover table-condensed\")\n",
    "            if table:\n",
    "                tbody = table.find(\"tbody\")\n",
    "                if tbody:\n",
    "                    for row in tbody.find_all(\"tr\"):\n",
    "                        cells = [td.get_text(strip=True).replace('\\xa0', ' ') for td in row.find_all(\"td\")]\n",
    "                        if cells:\n",
    "                            all_rows.append(cells)\n",
    "\n",
    "# Column headers (based on the HTML structure you showed)\n",
    "columns = [\n",
    "    \"College Code\", \"College Name\", \"Branch Code\", \"Branch Name\",\n",
    "    \"OC\", \"BC\", \"BCM\", \"MBC\", \"MBCDNC\", \"MBCV\", \"SC\", \"SCA\", \"ST\"\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(all_rows, columns=columns)\n",
    "\n",
    "# Save to CSV or Excel\n",
    "df.to_csv(\"tnea_data.csv\", index=False)\n",
    "# or\n",
    "df.to_json(\"tnea_data.json\", orient=\"records\", indent=2)\n",
    "\n",
    "print(f\"Scraped {len(df)} rows from {len(os.listdir(folder_path))} HTML files and saved to 'tnea_data.json'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dfaab8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tneacutoff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
